from openai import OpenAI
import os

# Chemins vers les fichiers de code
create_dataset = "benchmark-part-1/0_create_dataset.py"
import_bench = "benchmark-part-1/1_import_benchmark.py"
column_bench = "benchmark-part-1/2_create_column_benchmark.py"
filter_bench = "benchmark-part-1/3_filter_benchmark.py"
groupby_bench = "benchmark-part-1/4_groupby_benchmark.py"
markdown_file = "benchmark_v1.md"

# Fonction pour lire le contenu d'un fichier
def read_file(file_path):
    with open(file_path, 'r') as file:
        return file.read()

# Lecture du contenu des fichiers
create_dataset_code = read_file(create_dataset)
import_bench_code = read_file(import_bench)
column_bench_code = read_file(column_bench)
filter_bench_code = read_file(filter_bench)
groupby_bench_code = read_file(markdown_file)

# Pr√©paration du prompt pour l'API ChatGPT
prompt = f"""
You're a technical writer tasked with creating a Markdown blog post tutorial explaining what is Polars, how to use them and why it is more efficient than pandas. 
The tutorial is focused on simple data manipulation and a benchmark between Polars and Pandas. Here's the content from the files updated to add inference step and the code to use the artefact generated by this part:

**1. Dataset creation (`{create_dataset}`):**
```python
{create_dataset_code}
```
**2. Benchmark import (`{import_bench_code}`):**
```python
{import_bench_code}
```
**3. Benchmark columns creation (`{column_bench}`):**
```python
{column_bench_code}
**4. Benchmark columns filters (`{filter_bench}`):**
```python
{filter_bench_code}
**5. Benchmark groupby (`{groupby_bench}`):**
```python
{groupby_bench_code}
```
"""

response = client.chat.completions.create(
  model="gpt-4o-mini",
  messages=[
    {"role": "system", "content": "You are a technical writer and Senior Data Scientist."},
    {"role": "user", "content": prompt}]
)
markdown_content = response.choices[0].message.content.strip()

with open("benchmark_v1.md", "w") as md_file:
    md_file.write(markdown_content)

print("Markdown file 'benchmark_v1.md' has been created.")

additional_prompt = f"""
Please add a section to the existing content discussing on the reason why Polars has to be in the data scientist tools. Especially for data engineering part. 
I want to get the whole article in output. Not just the part about the reason why Polars has to be...
Here is the current content of the Markdown file:

{markdown_content}
"""

response_additional = client.chat.completions.create(
model="gpt-4o-mini",
messages=[
{"role": "system", "content": "You are a technical writer and Senior Data Scientist."},
{"role": "user", "content": additional_prompt}]
)

updated_markdown_content = response_additional.choices[0].message.content.strip()

with open("benchmark_v2.md", "w") as md_file:
    md_file.write(updated_markdown_content)

print(f"Markdown file '{markdown_file}' has been updated with additional content on pipelines and steps.")